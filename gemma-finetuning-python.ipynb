{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:11:23.168872Z",
     "iopub.status.busy": "2024-03-22T06:11:23.168165Z",
     "iopub.status.idle": "2024-03-22T06:11:36.422447Z",
     "shell.execute_reply": "2024-03-22T06:11:36.421675Z",
     "shell.execute_reply.started": "2024-03-22T06:11:23.168835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 06:11:25.663035: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-22 06:11:25.663136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-22 06:11:25.776459: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # you can also use tensorflow or torch\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = (\n",
    "    \"1.00\"  # avoid memory fragmentation on JAX backend.\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import keras_nlp\n",
    "import keras\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:11:36.424458Z",
     "iopub.status.busy": "2024-03-22T06:11:36.423971Z",
     "iopub.status.idle": "2024-03-22T06:11:37.048816Z",
     "shell.execute_reply": "2024-03-22T06:11:37.047837Z",
     "shell.execute_reply.started": "2024-03-22T06:11:36.424434Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>text</th>\n",
       "      <th>input</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>```python\\ntasks = []\\nwhile True:\\n    task =...</td>\n",
       "      <td>Help me set up my daily to-do list! Setting up...</td>\n",
       "      <td>Setting up your daily to-do list...</td>\n",
       "      <td>Help me set up my daily to-do list!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>```python\\nshopping_list = {}\\nwhile True:\\n  ...</td>\n",
       "      <td>Create a shopping list based on my inputs! Cre...</td>\n",
       "      <td>Creating a shopping list...</td>\n",
       "      <td>Create a shopping list based on my inputs!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>```python\\ntotal_time = 0\\nfor i in range(1, 8...</td>\n",
       "      <td>Calculate how much time I spend on my phone pe...</td>\n",
       "      <td>Calculating weekly phone usage...</td>\n",
       "      <td>Calculate how much time I spend on my phone pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>```python\\ntotal_bill = float(input('Enter the...</td>\n",
       "      <td>Help me split the bill among my friends! Split...</td>\n",
       "      <td>Splitting the bill...</td>\n",
       "      <td>Help me split the bill among my friends!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>```python\\nmovie_list = {}\\nwhile True:\\n    g...</td>\n",
       "      <td>Organize my movie list into genres! Organizing...</td>\n",
       "      <td>Organizing your movie list...</td>\n",
       "      <td>Organize my movie list into genres!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              output  \\\n",
       "0  ```python\\ntasks = []\\nwhile True:\\n    task =...   \n",
       "1  ```python\\nshopping_list = {}\\nwhile True:\\n  ...   \n",
       "2  ```python\\ntotal_time = 0\\nfor i in range(1, 8...   \n",
       "3  ```python\\ntotal_bill = float(input('Enter the...   \n",
       "4  ```python\\nmovie_list = {}\\nwhile True:\\n    g...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Help me set up my daily to-do list! Setting up...   \n",
       "1  Create a shopping list based on my inputs! Cre...   \n",
       "2  Calculate how much time I spend on my phone pe...   \n",
       "3  Help me split the bill among my friends! Split...   \n",
       "4  Organize my movie list into genres! Organizing...   \n",
       "\n",
       "                                 input  \\\n",
       "0  Setting up your daily to-do list...   \n",
       "1          Creating a shopping list...   \n",
       "2    Calculating weekly phone usage...   \n",
       "3                Splitting the bill...   \n",
       "4        Organizing your movie list...   \n",
       "\n",
       "                                         instruction  \n",
       "0                Help me set up my daily to-do list!  \n",
       "1         Create a shopping list based on my inputs!  \n",
       "2  Calculate how much time I spend on my phone pe...  \n",
       "3           Help me split the bill among my friends!  \n",
       "4                Organize my movie list into genres!  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read Dataset and show first five Rows\n",
    "df = pd.read_parquet(\"/kaggle/input/parquetfile-python-25k/0000.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:11:37.050388Z",
     "iopub.status.busy": "2024-03-22T06:11:37.050101Z",
     "iopub.status.idle": "2024-03-22T06:11:39.166115Z",
     "shell.execute_reply": "2024-03-22T06:11:39.165115Z",
     "shell.execute_reply.started": "2024-03-22T06:11:37.050364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "# define gemmma tokenizer\n",
    "tokenizer = keras_nlp.models.GemmaTokenizer.from_preset(\"gemma_instruct_2b_en\")\n",
    "\n",
    "\n",
    "def get_text_token_len(df_column: pd.Series) -> tuple[list, list]:\n",
    "    \"\"\"\n",
    "    Calculates the length of texts and their tokenized forms from a pandas Series.\n",
    "\n",
    "    Parameters:\n",
    "    - df_column (pd.Series): A pandas Series containing text data to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing two lists:\n",
    "        - The first list contains the lengths of the texts in words.\n",
    "        - The second list contains the lengths of the tokenized texts in tokens.\n",
    "    \"\"\"\n",
    "    text_len = []\n",
    "    token_len = []\n",
    "\n",
    "    for text in df_column.values:\n",
    "        length = len(text.split())\n",
    "        text_len.append(length)\n",
    "\n",
    "    for text in df_column.values:\n",
    "        tokens = tokenizer(text)\n",
    "        token_len.append(len(tokens))\n",
    "\n",
    "    return text_len, token_len\n",
    "\n",
    "\n",
    "def get_prep_gemma(instruction: list, output: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a DataFrame from instruction and output lists, preprocesses it for Gemma,\n",
    "    and appends text and token lengths before returning the processed DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - instruction (list): A list of instruction texts.\n",
    "    - output (list): A list of outputs corresponding to each instruction.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A pandas DataFrame containing the original instructions and outputs,\n",
    "      preprocessed text for Gemma, lengths of preprocessed texts in words and tokens,\n",
    "      with duplicates removed and sorted by token length in descending order.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame({\"instruction\": instruction, \"output\": output})\n",
    "\n",
    "    print(f\"Len DataFrame: {len(df)}\")\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna()\n",
    "    print(f\"Len DataFrame without Dups/NaN's: {len(df)}\")\n",
    "\n",
    "    data = df.apply(\n",
    "        lambda row: f\"Instruction:\\n{row['instruction']}\\n\\nResponse:\\n{row['output']}\",\n",
    "        axis=1,\n",
    "    ).values.tolist()\n",
    "\n",
    "    df[\"prep_gemma\"] = data\n",
    "\n",
    "    text_len, token_len = get_text_token_len(df_column=df[\"prep_gemma\"])\n",
    "\n",
    "    df[\"text_len_gemma\"] = text_len\n",
    "    df[\"token_len_gemma\"] = token_len\n",
    "    df = df.sort_values(by=\"token_len_gemma\", ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:11:39.169456Z",
     "iopub.status.busy": "2024-03-22T06:11:39.169005Z",
     "iopub.status.idle": "2024-03-22T06:12:47.339249Z",
     "shell.execute_reply": "2024-03-22T06:12:47.338313Z",
     "shell.execute_reply.started": "2024-03-22T06:11:39.169423Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len DataFrame: 49626\n",
      "Len DataFrame without Dups/NaN's: 24813\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>prep_gemma</th>\n",
       "      <th>text_len_gemma</th>\n",
       "      <th>token_len_gemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21722</th>\n",
       "      <td>Teacher:In this task, you are given inputs i a...</td>\n",
       "      <td>Sure, I can solve this task. The given integer...</td>\n",
       "      <td>Instruction:\\nTeacher:In this task, you are gi...</td>\n",
       "      <td>223</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21859</th>\n",
       "      <td>Detailed Instructions: In this task, you are g...</td>\n",
       "      <td>To accomplish this task, we will follow these ...</td>\n",
       "      <td>Instruction:\\nDetailed Instructions: In this t...</td>\n",
       "      <td>198</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21887</th>\n",
       "      <td>In this task you will be given two lists of nu...</td>\n",
       "      <td>To find the intersection between the two lists...</td>\n",
       "      <td>Instruction:\\nIn this task you will be given t...</td>\n",
       "      <td>281</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17244</th>\n",
       "      <td>Create a Python code generator for drawing a 3...</td>\n",
       "      <td>```python\\nimport pyglet\\n#cube window\\nwindow...</td>\n",
       "      <td>Instruction:\\nCreate a Python code generator f...</td>\n",
       "      <td>142</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22073</th>\n",
       "      <td>I have huge data in a directory tree format li...</td>\n",
       "      <td>Yes, it is possible to write a script that can...</td>\n",
       "      <td>Instruction:\\nI have huge data in a directory ...</td>\n",
       "      <td>300</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instruction  \\\n",
       "21722  Teacher:In this task, you are given inputs i a...   \n",
       "21859  Detailed Instructions: In this task, you are g...   \n",
       "21887  In this task you will be given two lists of nu...   \n",
       "17244  Create a Python code generator for drawing a 3...   \n",
       "22073  I have huge data in a directory tree format li...   \n",
       "\n",
       "                                                  output  \\\n",
       "21722  Sure, I can solve this task. The given integer...   \n",
       "21859  To accomplish this task, we will follow these ...   \n",
       "21887  To find the intersection between the two lists...   \n",
       "17244  ```python\\nimport pyglet\\n#cube window\\nwindow...   \n",
       "22073  Yes, it is possible to write a script that can...   \n",
       "\n",
       "                                              prep_gemma  text_len_gemma  \\\n",
       "21722  Instruction:\\nTeacher:In this task, you are gi...             223   \n",
       "21859  Instruction:\\nDetailed Instructions: In this t...             198   \n",
       "21887  Instruction:\\nIn this task you will be given t...             281   \n",
       "17244  Instruction:\\nCreate a Python code generator f...             142   \n",
       "22073  Instruction:\\nI have huge data in a directory ...             300   \n",
       "\n",
       "       token_len_gemma  \n",
       "21722              481  \n",
       "21859              479  \n",
       "21887              477  \n",
       "17244              476  \n",
       "22073              476  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = df[\"instruction\"].tolist()\n",
    "output = df[\"output\"].tolist()\n",
    "\n",
    "# preprocessing pipeline\n",
    "df = get_prep_gemma(instruction=instruction, output=output)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:12:47.340972Z",
     "iopub.status.busy": "2024-03-22T06:12:47.340609Z",
     "iopub.status.idle": "2024-03-22T06:12:47.361776Z",
     "shell.execute_reply": "2024-03-22T06:12:47.360801Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.340941Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Df 24813\n",
      "Len Df with more than 10 Text Words and less than 257 Tokens:22084\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>prep_gemma</th>\n",
       "      <th>text_len_gemma</th>\n",
       "      <th>token_len_gemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21244</th>\n",
       "      <td>Create a cover letter to apply for a job as a ...</td>\n",
       "      <td>Dear [Hiring Manager's Name],\\n\\nI am writing ...</td>\n",
       "      <td>Instruction:\\nCreate a cover letter to apply f...</td>\n",
       "      <td>210</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22471</th>\n",
       "      <td>How would I make Python return something like ...</td>\n",
       "      <td>Yes, that is correct. To create and return a d...</td>\n",
       "      <td>Instruction:\\nHow would I make Python return s...</td>\n",
       "      <td>134</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21367</th>\n",
       "      <td>Write a function to design a chessboard</td>\n",
       "      <td>Here is a function to create a text-based ches...</td>\n",
       "      <td>Instruction:\\nWrite a function to design a che...</td>\n",
       "      <td>156</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24762</th>\n",
       "      <td>Design a class in Python that computes the fre...</td>\n",
       "      <td>\"\"\"\\nDesign a class to compute the frequency o...</td>\n",
       "      <td>Instruction:\\nDesign a class in Python that co...</td>\n",
       "      <td>121</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Turn the following tutorial for Vera's Lobbies...</td>\n",
       "      <td>```python\\n# Step-by-Step Tutorial for Vera's ...</td>\n",
       "      <td>Instruction:\\nTurn the following tutorial for ...</td>\n",
       "      <td>135</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instruction  \\\n",
       "21244  Create a cover letter to apply for a job as a ...   \n",
       "22471  How would I make Python return something like ...   \n",
       "21367            Write a function to design a chessboard   \n",
       "24762  Design a class in Python that computes the fre...   \n",
       "232    Turn the following tutorial for Vera's Lobbies...   \n",
       "\n",
       "                                                  output  \\\n",
       "21244  Dear [Hiring Manager's Name],\\n\\nI am writing ...   \n",
       "22471  Yes, that is correct. To create and return a d...   \n",
       "21367  Here is a function to create a text-based ches...   \n",
       "24762  \"\"\"\\nDesign a class to compute the frequency o...   \n",
       "232    ```python\\n# Step-by-Step Tutorial for Vera's ...   \n",
       "\n",
       "                                              prep_gemma  text_len_gemma  \\\n",
       "21244  Instruction:\\nCreate a cover letter to apply f...             210   \n",
       "22471  Instruction:\\nHow would I make Python return s...             134   \n",
       "21367  Instruction:\\nWrite a function to design a che...             156   \n",
       "24762  Instruction:\\nDesign a class in Python that co...             121   \n",
       "232    Instruction:\\nTurn the following tutorial for ...             135   \n",
       "\n",
       "       token_len_gemma  \n",
       "21244              256  \n",
       "22471              256  \n",
       "21367              256  \n",
       "24762              256  \n",
       "232                256  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gemma input limit is 256 tokens (because memory) and the model should not short instructions\n",
    "# we use only instructions that have more than 10 Words\n",
    "\n",
    "print(f\"Len Df {len(df)}\")\n",
    "df = df[df[\"text_len_gemma\"] > 10]\n",
    "df = df[df[\"token_len_gemma\"] < 257]\n",
    "print(f\"Len Df with more than 10 Text Words and less than 257 Tokens:{len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:12:47.363405Z",
     "iopub.status.busy": "2024-03-22T06:12:47.363042Z",
     "iopub.status.idle": "2024-03-22T06:12:47.374296Z",
     "shell.execute_reply": "2024-03-22T06:12:47.373314Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.363373Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>prep_gemma</th>\n",
       "      <th>text_len_gemma</th>\n",
       "      <th>token_len_gemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24672</th>\n",
       "      <td>Create a Python code to output the following t...</td>\n",
       "      <td>print(\"Hello, World!\")</td>\n",
       "      <td>Instruction:\\nCreate a Python code to output t...</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18392</th>\n",
       "      <td>Write a Python program to load the sklearn pac...</td>\n",
       "      <td>```python\\nimport sklearn\\n```</td>\n",
       "      <td>Instruction:\\nWrite a Python program to load t...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24309</th>\n",
       "      <td>Write Python code to print the \"Hello World!\" ...</td>\n",
       "      <td>print(\"Hello World!\")</td>\n",
       "      <td>Instruction:\\nWrite Python code to print the \"...</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>Name a popular programming language</td>\n",
       "      <td>One popular programming language is Python.</td>\n",
       "      <td>Instruction:\\nName a popular programming langu...</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21158</th>\n",
       "      <td>For the following string, print the last four ...</td>\n",
       "      <td>thon</td>\n",
       "      <td>Instruction:\\nFor the following string, print ...</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instruction  \\\n",
       "24672  Create a Python code to output the following t...   \n",
       "18392  Write a Python program to load the sklearn pac...   \n",
       "24309  Write Python code to print the \"Hello World!\" ...   \n",
       "21513                Name a popular programming language   \n",
       "21158  For the following string, print the last four ...   \n",
       "\n",
       "                                            output  \\\n",
       "24672                       print(\"Hello, World!\")   \n",
       "18392               ```python\\nimport sklearn\\n```   \n",
       "24309                        print(\"Hello World!\")   \n",
       "21513  One popular programming language is Python.   \n",
       "21158                                         thon   \n",
       "\n",
       "                                              prep_gemma  text_len_gemma  \\\n",
       "24672  Instruction:\\nCreate a Python code to output t...              13   \n",
       "18392  Instruction:\\nWrite a Python program to load t...              15   \n",
       "24309  Instruction:\\nWrite Python code to print the \"...              13   \n",
       "21513  Instruction:\\nName a popular programming langu...              13   \n",
       "21158  Instruction:\\nFor the following string, print ...              13   \n",
       "\n",
       "       token_len_gemma  \n",
       "24672               23  \n",
       "18392               23  \n",
       "24309               23  \n",
       "21513               19  \n",
       "21158               19  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:12:47.375807Z",
     "iopub.status.busy": "2024-03-22T06:12:47.375501Z",
     "iopub.status.idle": "2024-03-22T06:12:47.382528Z",
     "shell.execute_reply": "2024-03-22T06:12:47.381611Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.375785Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "Rewrite the following Python code to improve readability and to simplify the code start = 0\n",
      "end = 10\n",
      "while start < end:\n",
      "  print start\n",
      "  start = start + 1\n",
      "\n",
      "Response:\n",
      "```python\n",
      "for start in range(10):\n",
      "  print(start)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "\n",
    "print(random.choice(df[\"prep_gemma\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:12:47.384282Z",
     "iopub.status.busy": "2024-03-22T06:12:47.383769Z",
     "iopub.status.idle": "2024-03-22T06:12:47.394953Z",
     "shell.execute_reply": "2024-03-22T06:12:47.394069Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.384252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_gemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21244</th>\n",
       "      <td>Instruction:\\nCreate a cover letter to apply f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22471</th>\n",
       "      <td>Instruction:\\nHow would I make Python return s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21367</th>\n",
       "      <td>Instruction:\\nWrite a function to design a che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24762</th>\n",
       "      <td>Instruction:\\nDesign a class in Python that co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Instruction:\\nTurn the following tutorial for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prep_gemma\n",
       "21244  Instruction:\\nCreate a cover letter to apply f...\n",
       "22471  Instruction:\\nHow would I make Python return s...\n",
       "21367  Instruction:\\nWrite a function to design a che...\n",
       "24762  Instruction:\\nDesign a class in Python that co...\n",
       "232    Instruction:\\nTurn the following tutorial for ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unimportant columns\n",
    "\n",
    "df = df.drop(columns=[\"instruction\", \"output\", \"text_len_gemma\", \"token_len_gemma\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:12:47.396389Z",
     "iopub.status.busy": "2024-03-22T06:12:47.396071Z",
     "iopub.status.idle": "2024-03-22T06:12:47.406718Z",
     "shell.execute_reply": "2024-03-22T06:12:47.405843Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.396354Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_gemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Instruction:\\nCreate a cover letter to apply f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Instruction:\\nHow would I make Python return s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Instruction:\\nWrite a function to design a che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Instruction:\\nDesign a class in Python that co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Instruction:\\nTurn the following tutorial for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prep_gemma\n",
       "0  Instruction:\\nCreate a cover letter to apply f...\n",
       "1  Instruction:\\nHow would I make Python return s...\n",
       "2  Instruction:\\nWrite a function to design a che...\n",
       "3  Instruction:\\nDesign a class in Python that co...\n",
       "4  Instruction:\\nTurn the following tutorial for ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the index\n",
    "\n",
    "df = df.reset_index(drop=[\"index\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:12:47.410767Z",
     "iopub.status.busy": "2024-03-22T06:12:47.410421Z",
     "iopub.status.idle": "2024-03-22T06:12:47.786228Z",
     "shell.execute_reply": "2024-03-22T06:12:47.785415Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.410745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save preprocessed gemma csv\n",
    "\n",
    "df.to_csv(\"prep_gemma_22k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:12:47.787506Z",
     "iopub.status.busy": "2024-03-22T06:12:47.787245Z",
     "iopub.status.idle": "2024-03-22T06:12:47.792006Z",
     "shell.execute_reply": "2024-03-22T06:12:47.791159Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.787483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# configurations\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    preset = \"gemma_instruct_2b_en\"\n",
    "    sequence_length = 256\n",
    "    batch_size = 1\n",
    "    epochs = 1\n",
    "    lora_rank = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:12:47.793354Z",
     "iopub.status.busy": "2024-03-22T06:12:47.793091Z",
     "iopub.status.idle": "2024-03-22T06:13:48.791859Z",
     "shell.execute_reply": "2024-03-22T06:13:48.791019Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.793332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get model from keras_nlp (make sure youre authenticated)\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(CFG.preset)\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:13:48.793351Z",
     "iopub.status.busy": "2024-03-22T06:13:48.793084Z",
     "iopub.status.idle": "2024-03-22T06:13:49.258344Z",
     "shell.execute_reply": "2024-03-22T06:13:49.257472Z",
     "shell.execute_reply.started": "2024-03-22T06:13:48.793328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,536,384\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# enable lora, limit trainable paramters\n",
    "\n",
    "gemma_lm.backbone.enable_lora(rank=CFG.lora_rank)\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:13:49.260290Z",
     "iopub.status.busy": "2024-03-22T06:13:49.259548Z",
     "iopub.status.idle": "2024-03-22T06:13:49.291211Z",
     "shell.execute_reply": "2024-03-22T06:13:49.290436Z",
     "shell.execute_reply.started": "2024-03-22T06:13:49.260263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Limit the input sequence length to 256 (to control memory usage).\n",
    "gemma_lm.preprocessor.sequence_length = CFG.sequence_length\n",
    "\n",
    "# Use AdamW (a common optimizer for transformer models).\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Exclude layernorm and bias terms from decay.\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "# compile the model\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:13:49.292623Z",
     "iopub.status.busy": "2024-03-22T06:13:49.292372Z",
     "iopub.status.idle": "2024-03-22T06:13:49.300729Z",
     "shell.execute_reply": "2024-03-22T06:13:49.299869Z",
     "shell.execute_reply.started": "2024-03-22T06:13:49.292602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_gemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Instruction:\\nCreate a cover letter to apply f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Instruction:\\nHow would I make Python return s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Instruction:\\nWrite a function to design a che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Instruction:\\nDesign a class in Python that co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Instruction:\\nTurn the following tutorial for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prep_gemma\n",
       "0  Instruction:\\nCreate a cover letter to apply f...\n",
       "1  Instruction:\\nHow would I make Python return s...\n",
       "2  Instruction:\\nWrite a function to design a che...\n",
       "3  Instruction:\\nDesign a class in Python that co...\n",
       "4  Instruction:\\nTurn the following tutorial for ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:13:49.302330Z",
     "iopub.status.busy": "2024-03-22T06:13:49.302010Z",
     "iopub.status.idle": "2024-03-22T06:13:49.309816Z",
     "shell.execute_reply": "2024-03-22T06:13:49.308995Z",
     "shell.execute_reply.started": "2024-03-22T06:13:49.302299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# get data for model training\n",
    "\n",
    "data = df[\"prep_gemma\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T06:13:53.368013Z",
     "iopub.status.busy": "2024-03-22T06:13:53.367310Z",
     "iopub.status.idle": "2024-03-22T08:38:05.220029Z",
     "shell.execute_reply": "2024-03-22T08:38:05.219236Z",
     "shell.execute_reply.started": "2024-03-22T06:13:53.367982Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22084/22084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8650s\u001b[0m 391ms/step - loss: 0.5984 - sparse_categorical_accuracy: 0.7827\n"
     ]
    }
   ],
   "source": [
    "# train the model with 1 epoch, 1 batch_size (memory)\n",
    "\n",
    "history = gemma_lm.fit(data, epochs=CFG.epochs, batch_size=CFG.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T08:39:34.836588Z",
     "iopub.status.busy": "2024-03-22T08:39:34.835896Z",
     "iopub.status.idle": "2024-03-22T08:40:38.861403Z",
     "shell.execute_reply": "2024-03-22T08:40:38.860251Z",
     "shell.execute_reply.started": "2024-03-22T08:39:34.836558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "gemma_lm.save(\"gemma_41k.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T08:53:47.581543Z",
     "iopub.status.busy": "2024-03-22T08:53:47.580848Z",
     "iopub.status.idle": "2024-03-22T08:53:47.587178Z",
     "shell.execute_reply": "2024-03-22T08:53:47.586079Z",
     "shell.execute_reply.started": "2024-03-22T08:53:47.581512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_response(\n",
    "    instruction: str, gemma_model: keras.Model, max_length: int = 1024\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a response using a Gemma model based on the provided instruction.\n",
    "\n",
    "    Args:\n",
    "      instruction (str): The instruction or query for which a response is desired. This could be a question, a command, or any text requiring an AI-based response.\n",
    "      gemma_model (keras_nlp.Model): The pre-trained Gemma model used to generate the response.\n",
    "      max_length (int, optional): The maximum length of the generated response. Default is 1024 tokens.\n",
    "\n",
    "    Example:\n",
    "      instruction = \"What will the weather be like tomorrow?\"\n",
    "      gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "\n",
    "      generate_response(instruction, gemma_model, max_length = 256)\n",
    "    \"\"\"\n",
    "    response = \"\"\n",
    "    prompt = f\"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
    "    print(gemma_model.generate(prompt, max_length=max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T08:54:21.362765Z",
     "iopub.status.busy": "2024-03-22T08:54:21.362030Z",
     "iopub.status.idle": "2024-03-22T08:54:23.826409Z",
     "shell.execute_reply": "2024-03-22T08:54:23.825485Z",
     "shell.execute_reply.started": "2024-03-22T08:54:21.362716Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "How do you write a for loop in Python that prints numbers 1 to 5?\n",
      "\n",
      "Response:\n",
      "for x in range(1, 6):\n",
      " print(x)\n",
      "\n",
      "\n",
      "\n",
      "Instruction:\n",
      "Identify and correct the error in the following Python line: print('Hello world)\n",
      "\n",
      "Response:\n",
      "print('Hello world')\n",
      "\n",
      "\n",
      "\n",
      "Instruction:\n",
      "How do you add an element 'apple' to the end of a list named 'fruits' in Python?\n",
      "\n",
      "Response:\n",
      "fruits.append('apple')\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instructions = [\n",
    "    \"How do you write a for loop in Python that prints numbers 1 to 5?\",\n",
    "    \"Identify and correct the error in the following Python line: print('Hello world)\",\n",
    "    \"How do you add an element 'apple' to the end of a list named 'fruits' in Python?\",\n",
    "]\n",
    "\n",
    "# let the model answer common questions about python programming\n",
    "for instruction in instructions:\n",
    "    generate_response(instruction=instruction, gemma_model=gemma_lm)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T08:54:32.452258Z",
     "iopub.status.busy": "2024-03-22T08:54:32.451407Z",
     "iopub.status.idle": "2024-03-22T08:54:32.456539Z",
     "shell.execute_reply": "2024-03-22T08:54:32.455561Z",
     "shell.execute_reply.started": "2024-03-22T08:54:32.452225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "instruction_harder = \"\"\"Improve this Python snippet that tries to find and print the first non-repeating character in a string. It crashes for strings without non-repeating characters. Ensure it handles this case gracefully and optimizes for short strings.\n",
    "\n",
    "def first_non_repeating_character(s):\n",
    "    for char in s:\n",
    "        if s.count(char) == 1:\n",
    "            print(char)\n",
    "            break\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T08:55:23.958743Z",
     "iopub.status.busy": "2024-03-22T08:55:23.958024Z",
     "iopub.status.idle": "2024-03-22T08:55:25.743744Z",
     "shell.execute_reply": "2024-03-22T08:55:25.742806Z",
     "shell.execute_reply.started": "2024-03-22T08:55:23.958713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "Improve this Python snippet that tries to find and print the first non-repeating character in a string. It crashes for strings without non-repeating characters. Ensure it handles this case gracefully and optimizes for short strings.\n",
      "\n",
      "def first_non_repeating_character(s):\n",
      "    for char in s:\n",
      "        if s.count(char) == 1:\n",
      "            print(char)\n",
      "            break\n",
      "\n",
      "Response:\n",
      "```python\n",
      "def first_non_repeating_character(s):\n",
      "    for char in s:\n",
      "        if s.count(char) == 1:\n",
      "            print(char)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# let the model answer one \"harder\" question\n",
    "\n",
    "generate_response(instruction=instruction_harder, gemma_model=gemma_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not quite good! but the model just was trained on 22k Python Questions and Answers, 1 Batch Size and 256 max Tokens!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4475281,
     "sourceId": 7672449,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 5388,
     "sourceId": 11372,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
