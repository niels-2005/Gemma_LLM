{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 7672449,
     "sourceType": "datasetVersion",
     "datasetId": 4475281
    },
    {
     "sourceId": 11372,
     "sourceType": "modelInstanceVersion",
     "modelInstanceId": 5388
    }
   ],
   "dockerImageVersionId": 30673,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# import dependencies\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # you can also use tensorflow or torch\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = (\n",
    "    \"1.00\"  # avoid memory fragmentation on JAX backend.\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import keras_nlp\n",
    "import keras\n",
    "import random"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:11:23.168165Z",
     "iopub.execute_input": "2024-03-22T06:11:23.168872Z",
     "iopub.status.idle": "2024-03-22T06:11:36.422447Z",
     "shell.execute_reply.started": "2024-03-22T06:11:23.168835Z",
     "shell.execute_reply": "2024-03-22T06:11:36.421675Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "2024-03-22 06:11:25.663035: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-22 06:11:25.663136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-22 06:11:25.776459: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# read Dataset and show first five Rows\ndf = pd.read_parquet(\"/kaggle/input/parquetfile-python-25k/0000.parquet\")\ndf.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:11:36.423971Z",
     "iopub.execute_input": "2024-03-22T06:11:36.424458Z",
     "iopub.status.idle": "2024-03-22T06:11:37.048816Z",
     "shell.execute_reply.started": "2024-03-22T06:11:36.424434Z",
     "shell.execute_reply": "2024-03-22T06:11:37.047837Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "execution_count": 2,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                              output  \\\n0  ```python\\ntasks = []\\nwhile True:\\n    task =...   \n1  ```python\\nshopping_list = {}\\nwhile True:\\n  ...   \n2  ```python\\ntotal_time = 0\\nfor i in range(1, 8...   \n3  ```python\\ntotal_bill = float(input('Enter the...   \n4  ```python\\nmovie_list = {}\\nwhile True:\\n    g...   \n\n                                                text  \\\n0  Help me set up my daily to-do list! Setting up...   \n1  Create a shopping list based on my inputs! Cre...   \n2  Calculate how much time I spend on my phone pe...   \n3  Help me split the bill among my friends! Split...   \n4  Organize my movie list into genres! Organizing...   \n\n                                 input  \\\n0  Setting up your daily to-do list...   \n1          Creating a shopping list...   \n2    Calculating weekly phone usage...   \n3                Splitting the bill...   \n4        Organizing your movie list...   \n\n                                         instruction  \n0                Help me set up my daily to-do list!  \n1         Create a shopping list based on my inputs!  \n2  Calculate how much time I spend on my phone pe...  \n3           Help me split the bill among my friends!  \n4                Organize my movie list into genres!  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>text</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>```python\\ntasks = []\\nwhile True:\\n    task =...</td>\n      <td>Help me set up my daily to-do list! Setting up...</td>\n      <td>Setting up your daily to-do list...</td>\n      <td>Help me set up my daily to-do list!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>```python\\nshopping_list = {}\\nwhile True:\\n  ...</td>\n      <td>Create a shopping list based on my inputs! Cre...</td>\n      <td>Creating a shopping list...</td>\n      <td>Create a shopping list based on my inputs!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>```python\\ntotal_time = 0\\nfor i in range(1, 8...</td>\n      <td>Calculate how much time I spend on my phone pe...</td>\n      <td>Calculating weekly phone usage...</td>\n      <td>Calculate how much time I spend on my phone pe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>```python\\ntotal_bill = float(input('Enter the...</td>\n      <td>Help me split the bill among my friends! Split...</td>\n      <td>Splitting the bill...</td>\n      <td>Help me split the bill among my friends!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>```python\\nmovie_list = {}\\nwhile True:\\n    g...</td>\n      <td>Organize my movie list into genres! Organizing...</td>\n      <td>Organizing your movie list...</td>\n      <td>Organize my movie list into genres!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# define gemmma tokenizer\n",
    "tokenizer = keras_nlp.models.GemmaTokenizer.from_preset(\"gemma_instruct_2b_en\")\n",
    "\n",
    "\n",
    "def get_text_token_len(df_column: pd.Series) -> tuple[list, list]:\n",
    "    \"\"\"\n",
    "    Calculates the length of texts and their tokenized forms from a pandas Series.\n",
    "\n",
    "    Parameters:\n",
    "    - df_column (pd.Series): A pandas Series containing text data to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing two lists:\n",
    "        - The first list contains the lengths of the texts in words.\n",
    "        - The second list contains the lengths of the tokenized texts in tokens.\n",
    "    \"\"\"\n",
    "    text_len = []\n",
    "    token_len = []\n",
    "\n",
    "    for text in df_column.values:\n",
    "        length = len(text.split())\n",
    "        text_len.append(length)\n",
    "\n",
    "    for text in df_column.values:\n",
    "        tokens = tokenizer(text)\n",
    "        token_len.append(len(tokens))\n",
    "\n",
    "    return text_len, token_len\n",
    "\n",
    "\n",
    "def get_prep_gemma(instruction: list, output: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a DataFrame from instruction and output lists, preprocesses it for Gemma,\n",
    "    and appends text and token lengths before returning the processed DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - instruction (list): A list of instruction texts.\n",
    "    - output (list): A list of outputs corresponding to each instruction.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A pandas DataFrame containing the original instructions and outputs,\n",
    "      preprocessed text for Gemma, lengths of preprocessed texts in words and tokens,\n",
    "      with duplicates removed and sorted by token length in descending order.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame({\"instruction\": instruction, \"output\": output})\n",
    "\n",
    "    print(f\"Len DataFrame: {len(df)}\")\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna()\n",
    "    print(f\"Len DataFrame without Dups/NaN's: {len(df)}\")\n",
    "\n",
    "    data = df.apply(\n",
    "        lambda row: f\"Instruction:\\n{row['instruction']}\\n\\nResponse:\\n{row['output']}\",\n",
    "        axis=1,\n",
    "    ).values.tolist()\n",
    "\n",
    "    df[\"prep_gemma\"] = data\n",
    "\n",
    "    text_len, token_len = get_text_token_len(df_column=df[\"prep_gemma\"])\n",
    "\n",
    "    df[\"text_len_gemma\"] = text_len\n",
    "    df[\"token_len_gemma\"] = token_len\n",
    "    df = df.sort_values(by=\"token_len_gemma\", ascending=False)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:11:37.050101Z",
     "iopub.execute_input": "2024-03-22T06:11:37.050388Z",
     "iopub.status.idle": "2024-03-22T06:11:39.166115Z",
     "shell.execute_reply.started": "2024-03-22T06:11:37.050364Z",
     "shell.execute_reply": "2024-03-22T06:11:39.165115Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "instruction = df[\"instruction\"].tolist()\noutput = df[\"output\"].tolist()\n\n# preprocessing pipeline\ndf = get_prep_gemma(instruction=instruction, output=output)\ndf.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:11:39.169005Z",
     "iopub.execute_input": "2024-03-22T06:11:39.169456Z",
     "iopub.status.idle": "2024-03-22T06:12:47.339249Z",
     "shell.execute_reply.started": "2024-03-22T06:11:39.169423Z",
     "shell.execute_reply": "2024-03-22T06:12:47.338313Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "Len DataFrame: 49626\nLen DataFrame without Dups/NaN's: 24813\n",
     "output_type": "stream"
    },
    {
     "execution_count": 4,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                             instruction  \\\n21722  Teacher:In this task, you are given inputs i a...   \n21859  Detailed Instructions: In this task, you are g...   \n21887  In this task you will be given two lists of nu...   \n17244  Create a Python code generator for drawing a 3...   \n22073  I have huge data in a directory tree format li...   \n\n                                                  output  \\\n21722  Sure, I can solve this task. The given integer...   \n21859  To accomplish this task, we will follow these ...   \n21887  To find the intersection between the two lists...   \n17244  ```python\\nimport pyglet\\n#cube window\\nwindow...   \n22073  Yes, it is possible to write a script that can...   \n\n                                              prep_gemma  text_len_gemma  \\\n21722  Instruction:\\nTeacher:In this task, you are gi...             223   \n21859  Instruction:\\nDetailed Instructions: In this t...             198   \n21887  Instruction:\\nIn this task you will be given t...             281   \n17244  Instruction:\\nCreate a Python code generator f...             142   \n22073  Instruction:\\nI have huge data in a directory ...             300   \n\n       token_len_gemma  \n21722              481  \n21859              479  \n21887              477  \n17244              476  \n22073              476  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>output</th>\n      <th>prep_gemma</th>\n      <th>text_len_gemma</th>\n      <th>token_len_gemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21722</th>\n      <td>Teacher:In this task, you are given inputs i a...</td>\n      <td>Sure, I can solve this task. The given integer...</td>\n      <td>Instruction:\\nTeacher:In this task, you are gi...</td>\n      <td>223</td>\n      <td>481</td>\n    </tr>\n    <tr>\n      <th>21859</th>\n      <td>Detailed Instructions: In this task, you are g...</td>\n      <td>To accomplish this task, we will follow these ...</td>\n      <td>Instruction:\\nDetailed Instructions: In this t...</td>\n      <td>198</td>\n      <td>479</td>\n    </tr>\n    <tr>\n      <th>21887</th>\n      <td>In this task you will be given two lists of nu...</td>\n      <td>To find the intersection between the two lists...</td>\n      <td>Instruction:\\nIn this task you will be given t...</td>\n      <td>281</td>\n      <td>477</td>\n    </tr>\n    <tr>\n      <th>17244</th>\n      <td>Create a Python code generator for drawing a 3...</td>\n      <td>```python\\nimport pyglet\\n#cube window\\nwindow...</td>\n      <td>Instruction:\\nCreate a Python code generator f...</td>\n      <td>142</td>\n      <td>476</td>\n    </tr>\n    <tr>\n      <th>22073</th>\n      <td>I have huge data in a directory tree format li...</td>\n      <td>Yes, it is possible to write a script that can...</td>\n      <td>Instruction:\\nI have huge data in a directory ...</td>\n      <td>300</td>\n      <td>476</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# gemma input limit is 256 tokens (because memory) and the model should not short instructions\n",
    "# we use only instructions that have more than 10 Words\n",
    "\n",
    "print(f\"Len Df {len(df)}\")\n",
    "df = df[df[\"text_len_gemma\"] > 10]\n",
    "df = df[df[\"token_len_gemma\"] < 257]\n",
    "print(f\"Len Df with more than 10 Text Words and less than 257 Tokens:{len(df)}\")\n",
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:12:47.340609Z",
     "iopub.execute_input": "2024-03-22T06:12:47.340972Z",
     "iopub.status.idle": "2024-03-22T06:12:47.361776Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.340941Z",
     "shell.execute_reply": "2024-03-22T06:12:47.360801Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "Len Df 24813\nLen Df with more than 10 Text Words and less than 257 Tokens:22084\n",
     "output_type": "stream"
    },
    {
     "execution_count": 5,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                             instruction  \\\n21244  Create a cover letter to apply for a job as a ...   \n22471  How would I make Python return something like ...   \n21367            Write a function to design a chessboard   \n24762  Design a class in Python that computes the fre...   \n232    Turn the following tutorial for Vera's Lobbies...   \n\n                                                  output  \\\n21244  Dear [Hiring Manager's Name],\\n\\nI am writing ...   \n22471  Yes, that is correct. To create and return a d...   \n21367  Here is a function to create a text-based ches...   \n24762  \"\"\"\\nDesign a class to compute the frequency o...   \n232    ```python\\n# Step-by-Step Tutorial for Vera's ...   \n\n                                              prep_gemma  text_len_gemma  \\\n21244  Instruction:\\nCreate a cover letter to apply f...             210   \n22471  Instruction:\\nHow would I make Python return s...             134   \n21367  Instruction:\\nWrite a function to design a che...             156   \n24762  Instruction:\\nDesign a class in Python that co...             121   \n232    Instruction:\\nTurn the following tutorial for ...             135   \n\n       token_len_gemma  \n21244              256  \n22471              256  \n21367              256  \n24762              256  \n232                256  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>output</th>\n      <th>prep_gemma</th>\n      <th>text_len_gemma</th>\n      <th>token_len_gemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21244</th>\n      <td>Create a cover letter to apply for a job as a ...</td>\n      <td>Dear [Hiring Manager's Name],\\n\\nI am writing ...</td>\n      <td>Instruction:\\nCreate a cover letter to apply f...</td>\n      <td>210</td>\n      <td>256</td>\n    </tr>\n    <tr>\n      <th>22471</th>\n      <td>How would I make Python return something like ...</td>\n      <td>Yes, that is correct. To create and return a d...</td>\n      <td>Instruction:\\nHow would I make Python return s...</td>\n      <td>134</td>\n      <td>256</td>\n    </tr>\n    <tr>\n      <th>21367</th>\n      <td>Write a function to design a chessboard</td>\n      <td>Here is a function to create a text-based ches...</td>\n      <td>Instruction:\\nWrite a function to design a che...</td>\n      <td>156</td>\n      <td>256</td>\n    </tr>\n    <tr>\n      <th>24762</th>\n      <td>Design a class in Python that computes the fre...</td>\n      <td>\"\"\"\\nDesign a class to compute the frequency o...</td>\n      <td>Instruction:\\nDesign a class in Python that co...</td>\n      <td>121</td>\n      <td>256</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>Turn the following tutorial for Vera's Lobbies...</td>\n      <td>```python\\n# Step-by-Step Tutorial for Vera's ...</td>\n      <td>Instruction:\\nTurn the following tutorial for ...</td>\n      <td>135</td>\n      <td>256</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "df.tail()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:12:47.363042Z",
     "iopub.execute_input": "2024-03-22T06:12:47.363405Z",
     "iopub.status.idle": "2024-03-22T06:12:47.374296Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.363373Z",
     "shell.execute_reply": "2024-03-22T06:12:47.373314Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "execution_count": 6,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                             instruction  \\\n24672  Create a Python code to output the following t...   \n18392  Write a Python program to load the sklearn pac...   \n24309  Write Python code to print the \"Hello World!\" ...   \n21513                Name a popular programming language   \n21158  For the following string, print the last four ...   \n\n                                            output  \\\n24672                       print(\"Hello, World!\")   \n18392               ```python\\nimport sklearn\\n```   \n24309                        print(\"Hello World!\")   \n21513  One popular programming language is Python.   \n21158                                         thon   \n\n                                              prep_gemma  text_len_gemma  \\\n24672  Instruction:\\nCreate a Python code to output t...              13   \n18392  Instruction:\\nWrite a Python program to load t...              15   \n24309  Instruction:\\nWrite Python code to print the \"...              13   \n21513  Instruction:\\nName a popular programming langu...              13   \n21158  Instruction:\\nFor the following string, print ...              13   \n\n       token_len_gemma  \n24672               23  \n18392               23  \n24309               23  \n21513               19  \n21158               19  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>output</th>\n      <th>prep_gemma</th>\n      <th>text_len_gemma</th>\n      <th>token_len_gemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24672</th>\n      <td>Create a Python code to output the following t...</td>\n      <td>print(\"Hello, World!\")</td>\n      <td>Instruction:\\nCreate a Python code to output t...</td>\n      <td>13</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>18392</th>\n      <td>Write a Python program to load the sklearn pac...</td>\n      <td>```python\\nimport sklearn\\n```</td>\n      <td>Instruction:\\nWrite a Python program to load t...</td>\n      <td>15</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>24309</th>\n      <td>Write Python code to print the \"Hello World!\" ...</td>\n      <td>print(\"Hello World!\")</td>\n      <td>Instruction:\\nWrite Python code to print the \"...</td>\n      <td>13</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>21513</th>\n      <td>Name a popular programming language</td>\n      <td>One popular programming language is Python.</td>\n      <td>Instruction:\\nName a popular programming langu...</td>\n      <td>13</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>21158</th>\n      <td>For the following string, print the last four ...</td>\n      <td>thon</td>\n      <td>Instruction:\\nFor the following string, print ...</td>\n      <td>13</td>\n      <td>19</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# sample\n\nprint(random.choice(df[\"prep_gemma\"]))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:12:47.375501Z",
     "iopub.execute_input": "2024-03-22T06:12:47.375807Z",
     "iopub.status.idle": "2024-03-22T06:12:47.382528Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.375785Z",
     "shell.execute_reply": "2024-03-22T06:12:47.381611Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "Instruction:\nRewrite the following Python code to improve readability and to simplify the code start = 0\nend = 10\nwhile start < end:\n  print start\n  start = start + 1\n\nResponse:\n```python\nfor start in range(10):\n  print(start)\n```\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# drop unimportant columns\n\ndf = df.drop(columns=[\"instruction\", \"output\", \"text_len_gemma\", \"token_len_gemma\"])\ndf.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:12:47.383769Z",
     "iopub.execute_input": "2024-03-22T06:12:47.384282Z",
     "iopub.status.idle": "2024-03-22T06:12:47.394953Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.384252Z",
     "shell.execute_reply": "2024-03-22T06:12:47.394069Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "execution_count": 8,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                              prep_gemma\n21244  Instruction:\\nCreate a cover letter to apply f...\n22471  Instruction:\\nHow would I make Python return s...\n21367  Instruction:\\nWrite a function to design a che...\n24762  Instruction:\\nDesign a class in Python that co...\n232    Instruction:\\nTurn the following tutorial for ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prep_gemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21244</th>\n      <td>Instruction:\\nCreate a cover letter to apply f...</td>\n    </tr>\n    <tr>\n      <th>22471</th>\n      <td>Instruction:\\nHow would I make Python return s...</td>\n    </tr>\n    <tr>\n      <th>21367</th>\n      <td>Instruction:\\nWrite a function to design a che...</td>\n    </tr>\n    <tr>\n      <th>24762</th>\n      <td>Instruction:\\nDesign a class in Python that co...</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>Instruction:\\nTurn the following tutorial for ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# reset the index\n\ndf = df.reset_index(drop=[\"index\"])\ndf.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:12:47.396071Z",
     "iopub.execute_input": "2024-03-22T06:12:47.396389Z",
     "iopub.status.idle": "2024-03-22T06:12:47.406718Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.396354Z",
     "shell.execute_reply": "2024-03-22T06:12:47.405843Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "execution_count": 9,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                          prep_gemma\n0  Instruction:\\nCreate a cover letter to apply f...\n1  Instruction:\\nHow would I make Python return s...\n2  Instruction:\\nWrite a function to design a che...\n3  Instruction:\\nDesign a class in Python that co...\n4  Instruction:\\nTurn the following tutorial for ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prep_gemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Instruction:\\nCreate a cover letter to apply f...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Instruction:\\nHow would I make Python return s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Instruction:\\nWrite a function to design a che...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Instruction:\\nDesign a class in Python that co...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Instruction:\\nTurn the following tutorial for ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# save preprocessed gemma csv\n\ndf.to_csv(\"prep_gemma_22k.csv\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:12:47.410421Z",
     "iopub.execute_input": "2024-03-22T06:12:47.410767Z",
     "iopub.status.idle": "2024-03-22T06:12:47.786228Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.410745Z",
     "shell.execute_reply": "2024-03-22T06:12:47.785415Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# configurations\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    preset = \"gemma_instruct_2b_en\"\n",
    "    sequence_length = 256\n",
    "    batch_size = 1\n",
    "    epochs = 1\n",
    "    lora_rank = 4"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:12:47.787245Z",
     "iopub.execute_input": "2024-03-22T06:12:47.787506Z",
     "iopub.status.idle": "2024-03-22T06:12:47.792006Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.787483Z",
     "shell.execute_reply": "2024-03-22T06:12:47.791159Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# get model from keras_nlp (make sure youre authenticated)\n\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(CFG.preset)\ngemma_lm.summary()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:12:47.793091Z",
     "iopub.execute_input": "2024-03-22T06:12:47.793354Z",
     "iopub.status.idle": "2024-03-22T06:13:48.791859Z",
     "shell.execute_reply.started": "2024-03-22T06:12:47.793332Z",
     "shell.execute_reply": "2024-03-22T06:13:48.791019Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "text": "Attaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# enable lora, limit trainable paramters\n\ngemma_lm.backbone.enable_lora(rank=CFG.lora_rank)\ngemma_lm.summary()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:13:48.793084Z",
     "iopub.execute_input": "2024-03-22T06:13:48.793351Z",
     "iopub.status.idle": "2024-03-22T06:13:49.258344Z",
     "shell.execute_reply.started": "2024-03-22T06:13:48.793328Z",
     "shell.execute_reply": "2024-03-22T06:13:49.257472Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,536,384\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (9.34 GB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# Limit the input sequence length to 256 (to control memory usage).\ngemma_lm.preprocessor.sequence_length = CFG.sequence_length\n\n# Use AdamW (a common optimizer for transformer models).\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n)\n\n# Exclude layernorm and bias terms from decay.\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\n# compile the model\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:13:49.259548Z",
     "iopub.execute_input": "2024-03-22T06:13:49.260290Z",
     "iopub.status.idle": "2024-03-22T06:13:49.291211Z",
     "shell.execute_reply.started": "2024-03-22T06:13:49.260263Z",
     "shell.execute_reply": "2024-03-22T06:13:49.290436Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:13:49.292372Z",
     "iopub.execute_input": "2024-03-22T06:13:49.292623Z",
     "iopub.status.idle": "2024-03-22T06:13:49.300729Z",
     "shell.execute_reply.started": "2024-03-22T06:13:49.292602Z",
     "shell.execute_reply": "2024-03-22T06:13:49.299869Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "execution_count": 15,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                          prep_gemma\n0  Instruction:\\nCreate a cover letter to apply f...\n1  Instruction:\\nHow would I make Python return s...\n2  Instruction:\\nWrite a function to design a che...\n3  Instruction:\\nDesign a class in Python that co...\n4  Instruction:\\nTurn the following tutorial for ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prep_gemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Instruction:\\nCreate a cover letter to apply f...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Instruction:\\nHow would I make Python return s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Instruction:\\nWrite a function to design a che...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Instruction:\\nDesign a class in Python that co...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Instruction:\\nTurn the following tutorial for ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# get data for model training\n\ndata = df[\"prep_gemma\"].tolist()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:13:49.302010Z",
     "iopub.execute_input": "2024-03-22T06:13:49.302330Z",
     "iopub.status.idle": "2024-03-22T06:13:49.309816Z",
     "shell.execute_reply.started": "2024-03-22T06:13:49.302299Z",
     "shell.execute_reply": "2024-03-22T06:13:49.308995Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# train the model with 1 epoch, 1 batch_size (memory)\n\nhistory = gemma_lm.fit(data, epochs=CFG.epochs, batch_size=CFG.batch_size)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T06:13:53.367310Z",
     "iopub.execute_input": "2024-03-22T06:13:53.368013Z",
     "iopub.status.idle": "2024-03-22T08:38:05.220029Z",
     "shell.execute_reply.started": "2024-03-22T06:13:53.367982Z",
     "shell.execute_reply": "2024-03-22T08:38:05.219236Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001b[1m22084/22084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8650s\u001b[0m 391ms/step - loss: 0.5984 - sparse_categorical_accuracy: 0.7827\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# save the model\n",
    "\n",
    "gemma_lm.save(\"gemma_41k.keras\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T08:39:34.835896Z",
     "iopub.execute_input": "2024-03-22T08:39:34.836588Z",
     "iopub.status.idle": "2024-03-22T08:40:38.861403Z",
     "shell.execute_reply.started": "2024-03-22T08:39:34.836558Z",
     "shell.execute_reply": "2024-03-22T08:40:38.860251Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_response(\n",
    "    instruction: str, gemma_model: keras.Model, max_length: int = 1024\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a response using a Gemma model based on the provided instruction.\n",
    "\n",
    "    Args:\n",
    "      instruction (str): The instruction or query for which a response is desired. This could be a question, a command, or any text requiring an AI-based response.\n",
    "      gemma_model (keras_nlp.Model): The pre-trained Gemma model used to generate the response.\n",
    "      max_length (int, optional): The maximum length of the generated response. Default is 1024 tokens.\n",
    "\n",
    "    Example:\n",
    "      instruction = \"What will the weather be like tomorrow?\"\n",
    "      gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "\n",
    "      generate_response(instruction, gemma_model, max_length = 256)\n",
    "    \"\"\"\n",
    "    response = \"\"\n",
    "    prompt = f\"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
    "    print(gemma_model.generate(prompt, max_length=max_length))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T08:53:47.580848Z",
     "iopub.execute_input": "2024-03-22T08:53:47.581543Z",
     "iopub.status.idle": "2024-03-22T08:53:47.587178Z",
     "shell.execute_reply.started": "2024-03-22T08:53:47.581512Z",
     "shell.execute_reply": "2024-03-22T08:53:47.586079Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "instructions = [\n",
    "    \"How do you write a for loop in Python that prints numbers 1 to 5?\",\n",
    "    \"Identify and correct the error in the following Python line: print('Hello world)\",\n",
    "    \"How do you add an element 'apple' to the end of a list named 'fruits' in Python?\",\n",
    "]\n",
    "\n",
    "# let the model answer common questions about python programming\n",
    "for instruction in instructions:\n",
    "    generate_response(instruction=instruction, gemma_model=gemma_lm)\n",
    "    print(\"\\n\\n\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T08:54:21.362030Z",
     "iopub.execute_input": "2024-03-22T08:54:21.362765Z",
     "iopub.status.idle": "2024-03-22T08:54:23.826409Z",
     "shell.execute_reply.started": "2024-03-22T08:54:21.362716Z",
     "shell.execute_reply": "2024-03-22T08:54:23.825485Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": "Instruction:\nHow do you write a for loop in Python that prints numbers 1 to 5?\n\nResponse:\nfor x in range(1, 6):\n print(x)\n\n\n\nInstruction:\nIdentify and correct the error in the following Python line: print('Hello world)\n\nResponse:\nprint('Hello world')\n\n\n\nInstruction:\nHow do you add an element 'apple' to the end of a list named 'fruits' in Python?\n\nResponse:\nfruits.append('apple')\n\n\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "instruction_harder = \"\"\"Improve this Python snippet that tries to find and print the first non-repeating character in a string. It crashes for strings without non-repeating characters. Ensure it handles this case gracefully and optimizes for short strings.\n\ndef first_non_repeating_character(s):\n    for char in s:\n        if s.count(char) == 1:\n            print(char)\n            break\"\"\"",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T08:54:32.451407Z",
     "iopub.execute_input": "2024-03-22T08:54:32.452258Z",
     "iopub.status.idle": "2024-03-22T08:54:32.456539Z",
     "shell.execute_reply.started": "2024-03-22T08:54:32.452225Z",
     "shell.execute_reply": "2024-03-22T08:54:32.455561Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# let the model answer one \"harder\" question\n\ngenerate_response(instruction=instruction_harder, gemma_model=gemma_lm)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T08:55:23.958024Z",
     "iopub.execute_input": "2024-03-22T08:55:23.958743Z",
     "iopub.status.idle": "2024-03-22T08:55:25.743744Z",
     "shell.execute_reply.started": "2024-03-22T08:55:23.958713Z",
     "shell.execute_reply": "2024-03-22T08:55:25.742806Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": "Instruction:\nImprove this Python snippet that tries to find and print the first non-repeating character in a string. It crashes for strings without non-repeating characters. Ensure it handles this case gracefully and optimizes for short strings.\n\ndef first_non_repeating_character(s):\n    for char in s:\n        if s.count(char) == 1:\n            print(char)\n            break\n\nResponse:\n```python\ndef first_non_repeating_character(s):\n    for char in s:\n        if s.count(char) == 1:\n            print(char)\n```\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# not quite good! but the model just was trained on 22k Python Questions and Answers",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}